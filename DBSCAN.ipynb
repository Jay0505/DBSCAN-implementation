{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def read_the_data(directory_path):\n",
    "    data = open(directory_path)\n",
    "    return data\n",
    "\n",
    "def convert_data__row_values_to_float(data):\n",
    "    data_as_list = []\n",
    "    shape_of_data = np.shape(data)[0]\n",
    "    for row in range(0, shape_of_data):\n",
    "        oneRow = data[0][row]\n",
    "        oneRowList = oneRow.split()\n",
    "        data_as_list.append(list(map(float, oneRowList)))\n",
    "    \n",
    "    return np.array(data_as_list)\n",
    "\n",
    "\n",
    " \n",
    "def DBSCAN(set_of_points, Eps, min_points):\n",
    "    \n",
    "    \n",
    "    no_of_points = np.shape(set_of_points)[0]\n",
    "    labels = np.zeros(no_of_points, dtype = np.int8)\n",
    "    cluster_id = 0\n",
    "    \n",
    "    '''initially, all the points are unclassified, i.e. have a label -1'''\n",
    "    for i in range(0, no_of_points):\n",
    "        if labels[i] == 0: \n",
    "            '''UNCLASSIFIED'''\n",
    "            labels, bool_value = Expland_cluster(set_of_points, i, cluster_id, labels, Eps, min_points)\n",
    "            if bool_value:\n",
    "                cluster_id = cluster_id + 1\n",
    "            \n",
    "    return labels\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "def region_Query(set_of_points, index, Eps):\n",
    "    Eps_neighbourhood = []\n",
    "    \n",
    "    no_of_points_in_dataset = np.shape(set_of_points)[0]\n",
    "    \n",
    "    for i in range(0, no_of_points_in_dataset):\n",
    "        \n",
    "        if np.linalg.norm(set_of_points[index] - set_of_points[i]) < Eps:\n",
    "            Eps_neighbourhood.append(i)\n",
    "        \n",
    "    return (Eps_neighbourhood)\n",
    "\n",
    "\n",
    "\n",
    "def change_cluster_Id(index, cluster_id, labels):\n",
    "    labels[index] = cluster_id\n",
    "    return labels\n",
    "    \n",
    "def Expland_cluster(set_of_points, index, cluster_id, labels, Eps, min_points):\n",
    "    \n",
    "    i = 0\n",
    "    Eps_neighbourhood_of_a_point = region_Query(set_of_points, index, Eps)\n",
    "    no_of_points_in_Eps_neighbourhood = np.shape(Eps_neighbourhood_of_a_point)[0]\n",
    "    \n",
    "    \n",
    "    if no_of_points_in_Eps_neighbourhood < min_points: \n",
    "        \n",
    "        '''NO CORE POINT'''\n",
    "        labels = change_cluster_Id(index, -1, labels)\n",
    "        return labels, False\n",
    "    \n",
    "    \n",
    "    else: \n",
    "        '''all points in Eps_neighbourhood are density reachable from point in set_of_points at index'''\n",
    "        for k in range(0, no_of_points_in_Eps_neighbourhood):\n",
    "            labels = change_cluster_Id(Eps_neighbourhood_of_a_point[k], cluster_id, labels)\n",
    "            \n",
    "        \n",
    "        required_index = ([i for i in range(0, no_of_points_in_Eps_neighbourhood) if Eps_neighbourhood_of_a_point[i] == index])\n",
    "        \n",
    "        del Eps_neighbourhood_of_a_point[required_index[0]]\n",
    "        no_of_points_in_Eps_neighbourhood = no_of_points_in_Eps_neighbourhood - 1\n",
    "    \n",
    "        while i < len(Eps_neighbourhood_of_a_point):\n",
    "\n",
    "            index_of_the_point_in_Eps_neigbourhood = Eps_neighbourhood_of_a_point[i]\n",
    "            Eps_neighbourhood_of_point_in_while = region_Query(set_of_points, index_of_the_point_in_Eps_neigbourhood, Eps)\n",
    "            no_of_points_in_Eps_neighbourhood_while = np.shape(Eps_neighbourhood_of_point_in_while)[0]\n",
    "\n",
    "            if no_of_points_in_Eps_neighbourhood_while >= min_points:\n",
    "                \n",
    "                Eps_neighbourhood_of_a_point = list(set(Eps_neighbourhood_of_a_point + Eps_neighbourhood_of_point_in_while))\n",
    "                \n",
    "                for j in range(0, no_of_points_in_Eps_neighbourhood_while):\n",
    "                    if labels[Eps_neighbourhood_of_point_in_while[j]] == 0:\n",
    "                        labels = change_cluster_Id(Eps_neighbourhood_of_point_in_while[j], cluster_id, labels)\n",
    "            \n",
    "#                 for i in range(0, no_of_points_in_Eps_neighbourhood_while):\n",
    "#                     index_of_a_point_in_the_points_set = Eps_neighbourhood_of_point_in_while[i]\n",
    "#                     if labels[index_of_a_point_in_the_points_set] == 0 or lables[index_of_a_point_in_the_points_set] == -1:\n",
    "                        \n",
    "#                         if labels[index_of_a_point_in_the_points_set] == 0:\n",
    "#                             Eps_neighbourhood_of_a_point.append(index_of_a_point_in_the_points_set)\n",
    "\n",
    "#                         labels = change_cluster_Id(index_of_a_point_in_the_points_set, cluster_id, labels)\n",
    "            i = i + 1\n",
    "        return labels, True\n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def get_indices_of_points_groupbed_by_cluster_id(labels):\n",
    "    cluster_ids_in_labels = set(labels)\n",
    "    labels_df = pd.DataFrame(labels, columns = ['id'])\n",
    "    labels_grouped_by_cluster_id = labels_df.groupby(['id'])\n",
    "    list_of_indices_grouped_by_ids = []\n",
    "\n",
    "    for id in cluster_ids_in_labels:\n",
    "        list_of_indices_grouped_by_ids.append(labels_grouped_by_cluster_id.get_group(id).index.values)\n",
    "\n",
    "    return list_of_indices_grouped_by_ids\n",
    "\n",
    "def calculate_center_points_of_cluster(list_of_indices_grouped_by_ids, data_df):\n",
    "    \n",
    "    no_of_clusters = len(list_of_indices_grouped_by_ids)\n",
    "    center_of_clusters = []\n",
    "    for i in range(0, no_of_clusters):\n",
    "        points = np.array([data_df[i] for i in list_of_indices_grouped_by_ids[0]])\n",
    "        center_of_clusters.append(points.mean(0))\n",
    "    \n",
    "    return np.array(center_of_clusters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_clusters(center_points_for_clusters, data_df, labels, is_kmeans, is_dataset1):\n",
    "    X, Y = get_points_as_X_and_Y(data_df)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(x = X, y = Y,c = labels, s=2)\n",
    "    \n",
    "        \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    plt.colorbar(scatter)\n",
    "    \n",
    "    if is_kmeans and is_dataset1:\n",
    "        fig.suptitle('data_1_kmeans', fontsize=10)\n",
    "    \n",
    "    elif not is_kmeans and is_dataset1:\n",
    "        fig.suptitle('data_1_DBSCAN', fontsize=10)\n",
    "    \n",
    "    elif not is_kmeans and not is_dataset1:\n",
    "        fig.suptitle('data_2_DBSCAN', fontsize=10)\n",
    "    \n",
    "    else:\n",
    "        fig.suptitle('data_2_kmeans', fontsize=10)\n",
    "        \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def get_points_as_X_and_Y(data_df):\n",
    "    X = [point[0] for point in data_df]\n",
    "    Y = [point[1] for point in data_df]\n",
    "    return X, Y\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.DataFrame(read_the_data(\"/dataset1.txt\"))\n",
    "data_df = convert_data__row_values_to_float(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### \n",
    "\n",
    "kmeans = KMeans(n_clusters = 2, random_state =42).fit(data_df)\n",
    "kmeans_labels_ = kmeans.labels_\n",
    "kmeans_cluster_centers = kmeans.cluster_centers_\n",
    "plot_clusters(kmeans_cluster_centers, data_df, kmeans_labels_, True, True)\n",
    "\n",
    "##################### \n",
    "\n",
    "labels = DBSCAN(data_df, 3, 40)\n",
    "list_of_indices_grouped_by_ids = get_indices_of_points_groupbed_by_cluster_id(labels)\n",
    "center_points_of_clusters = calculate_center_points_of_cluster(list_of_indices_grouped_by_ids, data_df)\n",
    "plot_clusters(center_points_of_clusters, data_df, labels, False, True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(read_the_data(\"/dataset2.txt\"))\n",
    "data2_df = convert_data__row_values_to_float(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2, random_state =42).fit(data2_df)\n",
    "kmeans_labels_2 = kmeans.labels_\n",
    "kmeans_cluster_centers_2 = kmeans.cluster_centers_\n",
    "plot_clusters(kmeans_cluster_centers_2, data2_df, kmeans_labels_2, True, False)\n",
    "\n",
    "#####################\n",
    "\n",
    "labels2 = DBSCAN(data2_df, 3, 10)\n",
    "list_of_indices_grouped_by_ids_2 = get_indices_of_points_groupbed_by_cluster_id(labels2)\n",
    "center_points_of_clusters_2 = calculate_center_points_of_cluster(list_of_indices_grouped_by_ids_2, data2_df)\n",
    "plot_clusters(center_points_of_clusters_2, data2_df, labels2, False, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
